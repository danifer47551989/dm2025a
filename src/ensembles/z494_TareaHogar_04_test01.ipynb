{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el viernes 01-agosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 02 de agosto a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wed Jul 30 20:54:05 2025'"
      ],
      "text/latex": [
       "'Wed Jul 30 20:54:05 2025'"
      ],
      "text/markdown": [
       "'Wed Jul 30 20:54:05 2025'"
      ],
      "text/plain": [
       "[1] \"Wed Jul 30 20:54:05 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 2327591</td><td>124.4</td><td>  3891071</td><td>207.9</td><td>  3891071</td><td>207.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>17721705</td><td>135.3</td><td>111768573</td><td>852.8</td><td>104531133</td><td>797.6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  2327591 & 124.4 &   3891071 & 207.9 &   3891071 & 207.9\\\\\n",
       "\tVcells & 17721705 & 135.3 & 111768573 & 852.8 & 104531133 & 797.6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  2327591 | 124.4 |   3891071 | 207.9 |   3891071 | 207.9 |\n",
       "| Vcells | 17721705 | 135.3 | 111768573 | 852.8 | 104531133 | 797.6 |\n",
       "\n"
      ],
      "text/plain": [
       "       used     (Mb)  gc trigger (Mb)  max used  (Mb) \n",
       "Ncells  2327591 124.4   3891071  207.9   3891071 207.9\n",
       "Vcells 17721705 135.3 111768573  852.8 104531133 797.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4943\n",
    "PARAM$semilla_primigenia <- 100019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-a\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# Hiperparámetros a optimizar en la Bayesian Optimization\n",
    "PARAM$lgbm$param_BO <- list(\n",
    "  num_leaves           = c(64L, 512L),\n",
    "  min_data_in_leaf     = c(50L, 5000L),\n",
    "  learning_rate        = c(0.005, 0.05),\n",
    "  feature_fraction     = c(0.3, 0.8),\n",
    "  bagging_fraction     = c(0.6, 0.9),\n",
    "  bagging_freq         = c(1L, 8L),\n",
    "  lambda_l1            = c(0.0, 8.0),\n",
    "  lambda_l2            = c(0.0, 10.0),\n",
    "  min_gain_to_split    = c(0.0, 0.1),\n",
    "  min_sum_hessian_in_leaf = c(0.001, 5.0),\n",
    "  max_depth            = c(4L, 12L),\n",
    "  max_bin              = c(31L, 255L),\n",
    "  min_data_in_bin      = c(3L, 100L),\n",
    "  drop_rate            = c(0.0, 0.2)\n",
    ")\n",
    "\n",
    "# Ejemplo de función objetivo\n",
    "lgbm_bayes_eval <- function(num_leaves,\n",
    "                            min_data_in_leaf,\n",
    "                            learning_rate,\n",
    "                            feature_fraction,\n",
    "                            bagging_fraction,\n",
    "                            bagging_freq,\n",
    "                            lambda_l1,\n",
    "                            lambda_l2,\n",
    "                            min_gain_to_split,\n",
    "                            min_sum_hessian_in_leaf) {\n",
    "\n",
    "  params <- c(\n",
    "    PARAM$lgbm$param_fijos,\n",
    "    list(\n",
    "      num_leaves = as.integer(num_leaves),\n",
    "      min_data_in_leaf = as.integer(min_data_in_leaf),\n",
    "      learning_rate = learning_rate,\n",
    "      feature_fraction = feature_fraction,\n",
    "      bagging_fraction = bagging_fraction,\n",
    "      bagging_freq = as.integer(bagging_freq),\n",
    "      lambda_l1 = lambda_l1,\n",
    "      lambda_l2 = lambda_l2,\n",
    "      min_gain_to_split = min_gain_to_split,\n",
    "      min_sum_hessian_in_leaf = min_sum_hessian_in_leaf\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Aquí entrenás el modelo y devolvés el AUC deseado\n",
    "  # result <- lgb.train(...)\n",
    "  # return(list(Score = result$best_score, nrounds = result$best_iter))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower = 500L, upper = 2500L),       # más rounds para LR bajos\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.003, upper = 0.05),        # LR más fino en parte baja\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.2, upper = 0.85),       # mayor diversidad en submuestreo de features\n",
    "  makeIntegerParam(\"num_leaves\", lower = 64L, upper = 400L),             # rango más estable, evita árboles muy complejos\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 3000L)      # mejor balance con num_leaves, previene overfitting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 65 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83617"
      ],
      "text/latex": [
       "83617"
      ],
      "text/markdown": [
       "83617"
      ],
      "text/plain": [
       "[1] 83617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set = PARAM$hyperparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Wed Jul 30 20:55:45 2025 AUC 0.926508382912155\n",
      "\n",
      "Wed Jul 30 20:56:27 2025 AUC 0.92813968128163\n",
      "\n",
      "Wed Jul 30 21:00:25 2025 AUC 0.927756026884234\n",
      "\n",
      "Wed Jul 30 21:01:51 2025 AUC 0.928596506250052\n",
      "\n",
      "Wed Jul 30 21:02:57 2025 AUC 0.926715054578924\n",
      "\n",
      "Wed Jul 30 21:03:32 2025 AUC 0.92643643593202\n",
      "\n",
      "Wed Jul 30 21:04:03 2025 AUC 0.928459956941637\n",
      "\n",
      "Wed Jul 30 21:05:53 2025 AUC 0.929607371711183\n",
      "\n",
      "Wed Jul 30 21:07:01 2025 AUC 0.927109825140495\n",
      "\n",
      "Wed Jul 30 21:07:34 2025 AUC 0.927332684003614\n",
      "\n",
      "Wed Jul 30 21:08:08 2025 AUC 0.926807631132529\n",
      "\n",
      "Wed Jul 30 21:09:29 2025 AUC 0.928570266180036\n",
      "\n",
      "Wed Jul 30 21:09:57 2025 AUC 0.927084760579428\n",
      "\n",
      "Wed Jul 30 21:11:45 2025 AUC 0.929647418753193\n",
      "\n",
      "Wed Jul 30 21:14:21 2025 AUC 0.929368349143497\n",
      "\n",
      "Wed Jul 30 21:15:12 2025 AUC 0.924642722576888\n",
      "\n",
      "Wed Jul 30 21:16:00 2025 AUC 0.929012213793315\n",
      "\n",
      "Wed Jul 30 21:16:46 2025 AUC 0.926510903328785\n",
      "\n",
      "Wed Jul 30 21:18:28 2025 AUC 0.928105345908556\n",
      "\n",
      "Wed Jul 30 21:18:46 2025 AUC 0.919616578933561\n",
      "\n",
      "[mbo] 0: num_iterations=1446; learning_rate=0.0371; feature_fraction=0.69; num_leaves=228; min_data_in_leaf=4749 : y = 0.927 : 52.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=699; learning_rate=0.0326; feature_fraction=0.578; num_leaves=318; min_data_in_leaf=2415 : y = 0.928 : 41.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1286; learning_rate=0.0452; feature_fraction=0.424; num_leaves=429; min_data_in_leaf=172 : y = 0.928 : 238.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1164; learning_rate=0.0142; feature_fraction=0.438; num_leaves=147; min_data_in_leaf=1113 : y = 0.929 : 86.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1202; learning_rate=0.0208; feature_fraction=0.385; num_leaves=461; min_data_in_leaf=2644 : y = 0.927 : 66.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=811; learning_rate=0.0103; feature_fraction=0.656; num_leaves=276; min_data_in_leaf=3481 : y = 0.926 : 34.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=444; learning_rate=0.0179; feature_fraction=0.603; num_leaves=357; min_data_in_leaf=1589 : y = 0.928 : 30.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1692; learning_rate=0.0282; feature_fraction=0.724; num_leaves=378; min_data_in_leaf=1525 : y = 0.93 : 110.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1396; learning_rate=0.0251; feature_fraction=0.371; num_leaves=259; min_data_in_leaf=3711 : y = 0.927 : 67.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=618; learning_rate=0.0424; feature_fraction=0.517; num_leaves=309; min_data_in_leaf=4240 : y = 0.927 : 33.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=880; learning_rate=0.0255; feature_fraction=0.797; num_leaves=193; min_data_in_leaf=3907 : y = 0.927 : 34.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1589; learning_rate=0.0119; feature_fraction=0.774; num_leaves=212; min_data_in_leaf=2263 : y = 0.929 : 80.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=485; learning_rate=0.0195; feature_fraction=0.469; num_leaves=471; min_data_in_leaf=3097 : y = 0.927 : 28.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1121; learning_rate=0.0316; feature_fraction=0.319; num_leaves=416; min_data_in_leaf=504 : y = 0.93 : 108.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1510; learning_rate=0.0396; feature_fraction=0.632; num_leaves=109; min_data_in_leaf=774 : y = 0.929 : 156.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=970; learning_rate=0.00798; feature_fraction=0.525; num_leaves=95; min_data_in_leaf=4932 : y = 0.925 : 50.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=551; learning_rate=0.0476; feature_fraction=0.557; num_leaves=342; min_data_in_leaf=971 : y = 0.929 : 48.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1011; learning_rate=0.048; feature_fraction=0.34; num_leaves=83; min_data_in_leaf=4287 : y = 0.927 : 46.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1790; learning_rate=0.0351; feature_fraction=0.477; num_leaves=493; min_data_in_leaf=3013 : y = 0.928 : 101.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=349; learning_rate=0.00614; feature_fraction=0.739; num_leaves=166; min_data_in_leaf=2029 : y = 0.92 : 18.8 secs : initdesign\n",
      "\n",
      "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 21:24:42 2025 AUC 0.926428825161783\n",
      "\n",
      "[mbo] 1: num_iterations=1800; learning_rate=0.0301; feature_fraction=0.501; num_leaves=457; min_data_in_leaf=73 : y = 0.926 : 348.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:26:15 2025 AUC 0.93046601065432\n",
      "\n",
      "[mbo] 2: num_iterations=1007; learning_rate=0.0315; feature_fraction=0.327; num_leaves=369; min_data_in_leaf=533 : y = 0.93 : 93.1 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:27:45 2025 AUC 0.928725691755943\n",
      "\n",
      "[mbo] 3: num_iterations=1088; learning_rate=0.0272; feature_fraction=0.645; num_leaves=351; min_data_in_leaf=1026 : y = 0.929 : 88.7 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:30:15 2025 AUC 0.927826706432096\n",
      "\n",
      "[mbo] 4: num_iterations=791; learning_rate=0.032; feature_fraction=0.302; num_leaves=390; min_data_in_leaf=136 : y = 0.928 : 149.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 5 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 21:31:24 2025 AUC 0.929896104719787\n",
      "\n",
      "[mbo] 5: num_iterations=754; learning_rate=0.0344; feature_fraction=0.338; num_leaves=279; min_data_in_leaf=601 : y = 0.93 : 65.8 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:33:31 2025 AUC 0.931091683329595\n",
      "\n",
      "[mbo] 6: num_iterations=1008; learning_rate=0.016; feature_fraction=0.655; num_leaves=251; min_data_in_leaf=549 : y = 0.931 : 125.7 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:35:45 2025 AUC 0.929331156853104\n",
      "\n",
      "[mbo] 7: num_iterations=1100; learning_rate=0.0418; feature_fraction=0.711; num_leaves=102; min_data_in_leaf=545 : y = 0.929 : 133.4 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:37:22 2025 AUC 0.929202007634563\n",
      "\n",
      "[mbo] 8: num_iterations=942; learning_rate=0.00501; feature_fraction=0.454; num_leaves=384; min_data_in_leaf=557 : y = 0.929 : 96.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:39:49 2025 AUC 0.92814731090478\n",
      "\n",
      "[mbo] 9: num_iterations=1003; learning_rate=0.0347; feature_fraction=0.303; num_leaves=255; min_data_in_leaf=141 : y = 0.928 : 145.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:42:38 2025 AUC 0.930265687986085\n",
      "\n",
      "[mbo] 10: num_iterations=1313; learning_rate=0.0318; feature_fraction=0.657; num_leaves=253; min_data_in_leaf=552 : y = 0.93 : 168.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 21:46:01 2025 AUC 0.92859997612585\n",
      "\n",
      "[mbo] 11: num_iterations=1193; learning_rate=0.0142; feature_fraction=0.658; num_leaves=144; min_data_in_leaf=166 : y = 0.929 : 197.1 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:47:34 2025 AUC 0.92849401809159\n",
      "\n",
      "[mbo] 12: num_iterations=1412; learning_rate=0.0315; feature_fraction=0.316; num_leaves=318; min_data_in_leaf=1133 : y = 0.928 : 92.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:49:41 2025 AUC 0.928927789862466\n",
      "\n",
      "[mbo] 13: num_iterations=979; learning_rate=0.0234; feature_fraction=0.66; num_leaves=239; min_data_in_leaf=559 : y = 0.929 : 126.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:51:17 2025 AUC 0.92953327684259\n",
      "\n",
      "[mbo] 14: num_iterations=932; learning_rate=0.0163; feature_fraction=0.648; num_leaves=367; min_data_in_leaf=702 : y = 0.93 : 95.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:53:09 2025 AUC 0.928958394159386\n",
      "\n",
      "[mbo] 15: num_iterations=972; learning_rate=0.00505; feature_fraction=0.743; num_leaves=260; min_data_in_leaf=641 : y = 0.929 : 111.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 16 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 21:55:08 2025 AUC 0.930055736295177\n",
      "\n",
      "[mbo] 16: num_iterations=1014; learning_rate=0.0175; feature_fraction=0.687; num_leaves=362; min_data_in_leaf=657 : y = 0.93 : 112.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:57:01 2025 AUC 0.929255526884053\n",
      "\n",
      "[mbo] 17: num_iterations=995; learning_rate=0.0332; feature_fraction=0.678; num_leaves=349; min_data_in_leaf=710 : y = 0.929 : 112.1 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 21:58:39 2025 AUC 0.929164003832275\n",
      "\n",
      "[mbo] 18: num_iterations=1064; learning_rate=0.015; feature_fraction=0.352; num_leaves=232; min_data_in_leaf=538 : y = 0.929 : 98.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:00:53 2025 AUC 0.929556172217518\n",
      "\n",
      "[mbo] 19: num_iterations=1422; learning_rate=0.00772; feature_fraction=0.786; num_leaves=250; min_data_in_leaf=856 : y = 0.93 : 132.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:05:20 2025 AUC 0.928485567003987\n",
      "\n",
      "[mbo] 20: num_iterations=1036; learning_rate=0.0156; feature_fraction=0.742; num_leaves=273; min_data_in_leaf=59 : y = 0.928 : 266.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 21 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 22:08:05 2025 AUC 0.928423090692377\n",
      "\n",
      "[mbo] 21: num_iterations=1196; learning_rate=0.015; feature_fraction=0.792; num_leaves=305; min_data_in_leaf=538 : y = 0.928 : 160.3 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:12:58 2025 AUC 0.927194624293644\n",
      "\n",
      "[mbo] 22: num_iterations=1504; learning_rate=0.0416; feature_fraction=0.587; num_leaves=363; min_data_in_leaf=78 : y = 0.927 : 292.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:14:56 2025 AUC 0.93017389284672\n",
      "\n",
      "[mbo] 23: num_iterations=1032; learning_rate=0.0308; feature_fraction=0.579; num_leaves=251; min_data_in_leaf=630 : y = 0.93 : 117.4 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:17:40 2025 AUC 0.928406081076446\n",
      "\n",
      "[mbo] 24: num_iterations=1565; learning_rate=0.0171; feature_fraction=0.458; num_leaves=253; min_data_in_leaf=577 : y = 0.928 : 163.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 25 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 22:19:44 2025 AUC 0.93006361488277\n",
      "\n",
      "[mbo] 25: num_iterations=984; learning_rate=0.0167; feature_fraction=0.607; num_leaves=463; min_data_in_leaf=542 : y = 0.93 : 120.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:21:45 2025 AUC 0.929254328000657\n",
      "\n",
      "[mbo] 26: num_iterations=1020; learning_rate=0.0138; feature_fraction=0.612; num_leaves=106; min_data_in_leaf=569 : y = 0.929 : 119.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:23:41 2025 AUC 0.929057609659625\n",
      "\n",
      "[mbo] 27: num_iterations=867; learning_rate=0.0178; feature_fraction=0.624; num_leaves=232; min_data_in_leaf=509 : y = 0.929 : 115.7 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:26:13 2025 AUC 0.929176826995085\n",
      "\n",
      "[mbo] 28: num_iterations=1129; learning_rate=0.00944; feature_fraction=0.623; num_leaves=256; min_data_in_leaf=510 : y = 0.929 : 150.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:29:11 2025 AUC 0.928683194307496\n",
      "\n",
      "[mbo] 29: num_iterations=708; learning_rate=0.0353; feature_fraction=0.7; num_leaves=251; min_data_in_leaf=62 : y = 0.929 : 176.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 30 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 22:30:47 2025 AUC 0.929647912382658\n",
      "\n",
      "[mbo] 30: num_iterations=1050; learning_rate=0.0158; feature_fraction=0.686; num_leaves=239; min_data_in_leaf=946 : y = 0.93 : 91.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:32:03 2025 AUC 0.928937155161625\n",
      "\n",
      "[mbo] 31: num_iterations=1000; learning_rate=0.0163; feature_fraction=0.382; num_leaves=221; min_data_in_leaf=922 : y = 0.929 : 75.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:32:47 2025 AUC 0.930333089637689\n",
      "\n",
      "[mbo] 32: num_iterations=450; learning_rate=0.0318; feature_fraction=0.396; num_leaves=241; min_data_in_leaf=574 : y = 0.93 : 43.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:33:35 2025 AUC 0.930737686239607\n",
      "\n",
      "[mbo] 33: num_iterations=510; learning_rate=0.0175; feature_fraction=0.673; num_leaves=251; min_data_in_leaf=847 : y = 0.931 : 47.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:34:08 2025 AUC 0.925546636826956\n",
      "\n",
      "[mbo] 34: num_iterations=423; learning_rate=0.0081; feature_fraction=0.435; num_leaves=245; min_data_in_leaf=1032 : y = 0.926 : 31.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:34:58 2025 AUC 0.930694153708773\n",
      "\n",
      "[mbo] 35: num_iterations=477; learning_rate=0.0196; feature_fraction=0.611; num_leaves=78; min_data_in_leaf=552 : y = 0.931 : 49.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:36:40 2025 AUC 0.930315152885092\n",
      "\n",
      "[mbo] 36: num_iterations=931; learning_rate=0.02; feature_fraction=0.515; num_leaves=98; min_data_in_leaf=57 : y = 0.93 : 100.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:37:48 2025 AUC 0.92818575869138\n",
      "\n",
      "[mbo] 37: num_iterations=598; learning_rate=0.0244; feature_fraction=0.648; num_leaves=89; min_data_in_leaf=79 : y = 0.928 : 67.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:39:13 2025 AUC 0.93062630006348\n",
      "\n",
      "[mbo] 38: num_iterations=1001; learning_rate=0.0311; feature_fraction=0.415; num_leaves=266; min_data_in_leaf=849 : y = 0.931 : 83.7 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:41:07 2025 AUC 0.930283521988224\n",
      "\n",
      "[mbo] 39: num_iterations=1002; learning_rate=0.0175; feature_fraction=0.607; num_leaves=156; min_data_in_leaf=622 : y = 0.93 : 113.8 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 40 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 22:41:53 2025 AUC 0.929446702787309\n",
      "\n",
      "[mbo] 40: num_iterations=415; learning_rate=0.0197; feature_fraction=0.668; num_leaves=198; min_data_in_leaf=840 : y = 0.929 : 39.4 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:44:46 2025 AUC 0.93038383206981\n",
      "\n",
      "[mbo] 41: num_iterations=1281; learning_rate=0.00523; feature_fraction=0.683; num_leaves=112; min_data_in_leaf=288 : y = 0.93 : 171.6 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:48:30 2025 AUC 0.930170769403618\n",
      "\n",
      "[mbo] 42: num_iterations=1639; learning_rate=0.0101; feature_fraction=0.653; num_leaves=331; min_data_in_leaf=514 : y = 0.93 : 223.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:49:25 2025 AUC 0.92919992563385\n",
      "\n",
      "[mbo] 43: num_iterations=454; learning_rate=0.0161; feature_fraction=0.686; num_leaves=205; min_data_in_leaf=573 : y = 0.929 : 55.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:51:47 2025 AUC 0.929369818694674\n",
      "\n",
      "[mbo] 44: num_iterations=1014; learning_rate=0.0163; feature_fraction=0.595; num_leaves=272; min_data_in_leaf=460 : y = 0.929 : 140.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 45 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 22:53:17 2025 AUC 0.928110009215025\n",
      "\n",
      "[mbo] 45: num_iterations=1005; learning_rate=0.0295; feature_fraction=0.368; num_leaves=470; min_data_in_leaf=792 : y = 0.928 : 83.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:54:46 2025 AUC 0.929447568034021\n",
      "\n",
      "[mbo] 46: num_iterations=812; learning_rate=0.0314; feature_fraction=0.58; num_leaves=140; min_data_in_leaf=666 : y = 0.929 : 88.4 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:56:45 2025 AUC 0.928556477097445\n",
      "\n",
      "[mbo] 47: num_iterations=1560; learning_rate=0.018; feature_fraction=0.419; num_leaves=251; min_data_in_leaf=1091 : y = 0.929 : 117.6 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:58:56 2025 AUC 0.929832461816073\n",
      "\n",
      "[mbo] 48: num_iterations=1035; learning_rate=0.0162; feature_fraction=0.664; num_leaves=116; min_data_in_leaf=550 : y = 0.93 : 130.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 22:59:58 2025 AUC 0.930928747597894\n",
      "\n",
      "[mbo] 49: num_iterations=623; learning_rate=0.02; feature_fraction=0.458; num_leaves=128; min_data_in_leaf=670 : y = 0.931 : 60.8 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:01:41 2025 AUC 0.929901610590536\n",
      "\n",
      "[mbo] 50: num_iterations=973; learning_rate=0.0313; feature_fraction=0.445; num_leaves=156; min_data_in_leaf=562 : y = 0.93 : 102.3 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:02:51 2025 AUC 0.929962698535098\n",
      "\n",
      "[mbo] 51: num_iterations=547; learning_rate=0.0186; feature_fraction=0.612; num_leaves=145; min_data_in_leaf=535 : y = 0.93 : 69.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 52 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 23:03:43 2025 AUC 0.929806372426879\n",
      "\n",
      "[mbo] 52: num_iterations=510; learning_rate=0.0203; feature_fraction=0.508; num_leaves=64; min_data_in_leaf=630 : y = 0.93 : 46.5 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:04:42 2025 AUC 0.929382473734353\n",
      "\n",
      "[mbo] 53: num_iterations=767; learning_rate=0.0193; feature_fraction=0.346; num_leaves=101; min_data_in_leaf=794 : y = 0.929 : 59.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:05:30 2025 AUC 0.927408536120446\n",
      "\n",
      "[mbo] 54: num_iterations=992; learning_rate=0.016; feature_fraction=0.708; num_leaves=465; min_data_in_leaf=2821 : y = 0.927 : 46.9 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:06:37 2025 AUC 0.93001870254469\n",
      "\n",
      "[mbo] 55: num_iterations=713; learning_rate=0.0246; feature_fraction=0.421; num_leaves=206; min_data_in_leaf=671 : y = 0.93 : 65.7 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:07:15 2025 AUC 0.927300444893497\n",
      "\n",
      "[mbo] 56: num_iterations=1038; learning_rate=0.0322; feature_fraction=0.741; num_leaves=75; min_data_in_leaf=4716 : y = 0.927 : 37.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:09:48 2025 AUC 0.930647825882081\n",
      "\n",
      "[mbo] 57: num_iterations=1174; learning_rate=0.0204; feature_fraction=0.528; num_leaves=125; min_data_in_leaf=140 : y = 0.931 : 153.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:12:34 2025 AUC 0.929997794315792\n",
      "\n",
      "[mbo] 58: num_iterations=1184; learning_rate=0.0215; feature_fraction=0.485; num_leaves=158; min_data_in_leaf=383 : y = 0.93 : 164.2 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:13:03 2025 AUC 0.928253521648406\n",
      "\n",
      "[mbo] 59: num_iterations=445; learning_rate=0.02; feature_fraction=0.511; num_leaves=117; min_data_in_leaf=2201 : y = 0.928 : 28.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 60 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 23:14:24 2025 AUC 0.929170648538351\n",
      "\n",
      "[mbo] 60: num_iterations=605; learning_rate=0.0403; feature_fraction=0.57; num_leaves=260; min_data_in_leaf=547 : y = 0.929 : 75.3 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:20:34 2025 AUC 0.928049686361395\n",
      "\n",
      "[mbo] 61: num_iterations=1346; learning_rate=0.00505; feature_fraction=0.678; num_leaves=288; min_data_in_leaf=113 : y = 0.928 : 369.1 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:23:06 2025 AUC 0.931549089526181\n",
      "\n",
      "[mbo] 62: num_iterations=1442; learning_rate=0.0195; feature_fraction=0.575; num_leaves=110; min_data_in_leaf=735 : y = 0.932 : 151.0 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:25:49 2025 AUC 0.930707516515392\n",
      "\n",
      "[mbo] 63: num_iterations=1622; learning_rate=0.0195; feature_fraction=0.544; num_leaves=125; min_data_in_leaf=810 : y = 0.931 : 162.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Jul 30 23:28:23 2025 AUC 0.928205303976426\n",
      "\n",
      "[mbo] 64: num_iterations=1240; learning_rate=0.0195; feature_fraction=0.531; num_leaves=109; min_data_in_leaf=438 : y = 0.928 : 149.1 secs : infill_ei\n",
      "\n",
      "Wed Jul 30 23:30:01 2025 AUC 0.929527597184814\n",
      "\n",
      "[mbo] 65: num_iterations=1018; learning_rate=0.0163; feature_fraction=0.576; num_leaves=302; min_data_in_leaf=855 : y = 0.93 : 97.1 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"opt.state\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mboContinue(opt.state):\n",
      "“Tuning ended with term.iter. No need to continue. Simply returning stored result.”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'num_leaves'\n",
       "5. 'min_data_in_leaf'\n",
       "6. 'y'\n",
       "7. 'dob'\n",
       "8. 'eol'\n",
       "9. 'error.message'\n",
       "10. 'exec.time'\n",
       "11. 'ei'\n",
       "12. 'error.model'\n",
       "13. 'train.time'\n",
       "14. 'prop.type'\n",
       "15. 'propose.time'\n",
       "16. 'se'\n",
       "17. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"   \"learning_rate\"    \"feature_fraction\" \"num_leaves\"      \n",
       " [5] \"min_data_in_leaf\" \"y\"                \"dob\"              \"eol\"             \n",
       " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
       "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
       "[17] \"mean\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(\"/content/buckets/b1/exp/HT4943\")  # Ajusta a la carpeta donde está tu experimento\n",
    "objs <- load(\"bayesiana.RDATA\")\n",
    "print(objs)  # Ver qué objetos hay (normalmente \"bayesiana_salida\" o \"opt.state\")\n",
    "if (\"opt.state\" %in% objs) {\n",
    "  bayesiana_salida <- mboContinue(opt.state)\n",
    "}\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
      "            <int>         <num>            <num>      <int>            <int>\n",
      "1:           1442    0.01951535        0.5754602        110              735\n",
      "[1] 0.9315491\n"
     ]
    }
   ],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>100019</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>-1</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>1442</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0195153484066421</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.575460186796097</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>110</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>735</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 100019\n",
       "\\item[\\$max\\_depth] -1\n",
       "\\item[\\$num\\_iterations] 1442\n",
       "\\item[\\$learning\\_rate] 0.0195153484066421\n",
       "\\item[\\$feature\\_fraction] 0.575460186796097\n",
       "\\item[\\$num\\_leaves] 110\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 735\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   100019\n",
       "$max_depth\n",
       ":   -1\n",
       "$num_iterations\n",
       ":   1442\n",
       "$learning_rate\n",
       ":   0.0195153484066421\n",
       "$feature_fraction\n",
       ":   0.575460186796097\n",
       "$num_leaves\n",
       ":   110\n",
       "$min_data_in_leaf\n",
       ":   735\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 100019\n",
       "\n",
       "$max_depth\n",
       "[1] -1\n",
       "\n",
       "$num_iterations\n",
       "[1] 1442\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.01951535\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.5754602\n",
       "\n",
       "$num_leaves\n",
       "[1] 110\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 735\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PARAM$lgbm$param_fijos <- list(\n",
    "  boosting = \"gbdt\",\n",
    "  objective = \"binary\",\n",
    "  metric = \"auc\",\n",
    "  first_metric_only = FALSE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE,\n",
    "  verbosity = -100,\n",
    "  seed = PARAM$semilla_primigenia,\n",
    "  max_depth = -1L,\n",
    "  num_iterations = 1200\n",
    ")\n",
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMHh7uNVIJkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
